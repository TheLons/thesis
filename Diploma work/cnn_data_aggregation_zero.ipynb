{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train_data and contact matrix\n",
      "Loaded successfully\n",
      "6812\n",
      "6905\n",
      "Amount of proteins, which we have after bounding:  504\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('Loading train_data and contact matrix')\n",
    "\n",
    "def load_data(data_name):\n",
    "    pkl_file = open(data_name + '.pkl', 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data\n",
    "\n",
    "#  Load data and target\n",
    "data_train = load_data('train_data')\n",
    "two_matrix = load_data('two_matrix_200')\n",
    "num_classes = 2\n",
    "print('Loaded successfully')\n",
    "\n",
    "data_features = pd.read_csv('pdb_and_features.csv')\n",
    "data_features = data_features.reset_index(drop=True)\n",
    "print(len(data_train))\n",
    "print(len(two_matrix))\n",
    "\n",
    "protein_len = []\n",
    "pdb_200 = []\n",
    "\n",
    "low_border = 25\n",
    "high_border = 40\n",
    "\n",
    "s = 0\n",
    "for i in range(len(two_matrix)):\n",
    "    if (np.shape(two_matrix[i][2])[0] <= high_border) and (np.shape(two_matrix[i][2])[0] >= low_border):\n",
    "        s +=1\n",
    "\n",
    "print('Amount of proteins, which we have after bounding: ', s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero-padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Apply zero-padding to make same size for all train and target samples\n",
    "\n",
    "target = []\n",
    "mm = high_border\n",
    "\n",
    "for i in range(len(two_matrix)):\n",
    "    \n",
    "    if (high_border >= np.shape(two_matrix[i][2])[0]) and (np.shape(two_matrix[i][2])[0] >= low_border):\n",
    "        \n",
    "        f = np.zeros((mm-np.shape(two_matrix[i][2])[0], np.shape(two_matrix[i][2])[0]))\n",
    "        f1 = np.zeros((mm, mm-np.shape(two_matrix[i][2])[0]))\n",
    "        bot = np.concatenate((two_matrix[i][2], f), axis=0)\n",
    "        target.append([two_matrix[i][0], np.concatenate((bot, f1), axis=1), len(two_matrix[i][2])])\n",
    "        \n",
    "\n",
    "train = []\n",
    "mm = high_border\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    \n",
    "    if (high_border >= np.shape(data_train[i][1])[0]) and (len(data_features.FASTA[i]) <= high_border) and \\\n",
    "            (len(data_features.FASTA[i]) >= low_border):\n",
    "        \n",
    "        f = np.zeros((mm-np.shape(data_train[i][1])[0], np.shape(data_train[i][1])[1]))\n",
    "        train.append([data_features.pdb_name[i], \n",
    "                      np.concatenate((data_train[i][1], f), axis=0), \n",
    "                      len(data_features.FASTA[i]),\n",
    "                      data_features.FASTA[i]])\n",
    "        \n",
    "    elif (len(data_features.FASTA[i]) <= high_border) and (len(data_features.FASTA[i]) >= low_border):\n",
    "        \n",
    "        train.append([data_features.pdb_name[i], \n",
    "                      data_train[i][1][:mm], \n",
    "                      len(data_features.FASTA[i]), \n",
    "                      data_features.FASTA[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train = []\n",
    "real_target = []\n",
    "\n",
    "for i in range(len(train)):\n",
    "    \n",
    "    for j in range(len(target)):\n",
    "        \n",
    "        if train[i][0] == target[j][0]:\n",
    "            if train[i][2] == target[j][2]:\n",
    "                real_train.append(train[i])\n",
    "                real_target.append(target[j])\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((474, 4), (474, 3))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(real_train), np.shape(real_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(39, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_train[134][2], real_target[134][2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_val_test, train_label, target_val_test = train_test_split(real_train, real_target, test_size=0.3, random_state=13)\n",
    "test, valid, test_label, valid_label = train_test_split(train_val_test, target_val_test, test_size=0.5, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 4), (71, 4))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train), np.shape(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 56)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[0][1].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some transformations to make train and target data\n",
    "# For neural networks\n",
    "\n",
    "def redo(x):\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(x)):\n",
    "        out.append(x[i][1])\n",
    "        \n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "def train_transform(x):\n",
    "    \n",
    "    x = redo(np.array(x))\n",
    "    x = np.expand_dims(x, axis=4)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def reshape_of_labels(x):\n",
    "    \n",
    "    lst1 = [[[0 for col in range(x.shape[2])] for col in range(x.shape[0])] for row in range(x.shape[1])]\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            for k in range(len(x[i][j])):\n",
    "                lst1[j][i][k] = x[i, j, k]\n",
    "                \n",
    "    return lst1\n",
    "\n",
    "\n",
    "def triangle_target_transform(x):\n",
    "    \n",
    "    x = redo(np.array(x))\n",
    "    \n",
    "    length = x.shape[1]\n",
    "    width = x.shape[2]\n",
    "        \n",
    "    x = np.array(list(map(lambda x: x.reshape(length, width)[np.triu_indices(width, k = 1)], x)))\n",
    "    \n",
    "    return x\n",
    "\n",
    "    \n",
    "def target_transform(x):\n",
    "    \n",
    "    x = triangle_target_transform(x)\n",
    "    print(x)\n",
    "    \n",
    "#     x_l = x.shape[0]\n",
    "#     x_w = x.shape[1]\n",
    "#     x = enc.fit_transform(x.reshape(-1, 1))\n",
    "#     x = x.reshape(x_l, x_w, num_classes)\n",
    "    \n",
    "#     print(x)\n",
    "#     x = reshape_of_labels(x)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "# def test_target_transform(x):\n",
    "    \n",
    "#     x = redo(np.array(x))\n",
    "#     x_w = x.shape[0]\n",
    "#     x_h = x.shape[1]\n",
    "#     x_l = x.shape[2]\n",
    "#     x = x.reshape(x_w, x_h*x_l)\n",
    "#     enc = OneHotEncoder(sparse=False)\n",
    "#     x = enc.fit_transform(x.reshape(-1, 1))\n",
    "#     x = x.reshape(x_w, x_h*x_l, num_classes)\n",
    "#     x = reshape_of_labels(x)\n",
    "#     return x\n",
    "\n",
    "\n",
    "def save_file(data, data_name):\n",
    "    \n",
    "    output = open(data_name + '.pkl', 'wb')\n",
    "    pickle.dump(data, output)\n",
    "    output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# machine learning preprocessing\n",
    "\n",
    "def machine_train_transform(x):\n",
    "    \n",
    "    x = redo(np.array(x))\n",
    "    out_matrix = []\n",
    "    out = []\n",
    "    dist = []\n",
    "    \n",
    "    for i in range(x.shape[0]):\n",
    "        for j in range(x.shape[1]):\n",
    "            for k in range(j + 1, x.shape[1]):\n",
    "                out.append(np.concatenate([x[i][j], x[i][k]]))\n",
    "                \n",
    "    return np.array(out)\n",
    "\n",
    "def machine_target_transform(x):\n",
    "    \n",
    "    x = triangle_target_transform(x)\n",
    "    \n",
    "    return x.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data for neural networks and machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-21-1d436b1208b3>:16: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  x = np.expand_dims(x, axis=4)\n"
     ]
    }
   ],
   "source": [
    "neural_train = train_transform(np.array(train))\n",
    "neural_test = train_transform(np.array(test))\n",
    "neural_valid = train_transform(np.array(valid))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data for neural networks and machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 1. 0. ... 1. 1. 1.]\n",
      " [1. 1. 0. ... 1. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n",
      "[[1. 1. 1. ... 1. 1. 1.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]]\n",
      "[[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 0. ... 1. 1. 1.]\n",
      " [1. 1. 1. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "neural_train_label = target_transform(np.array(train_label))\n",
    "neural_test_label = target_transform(np.array(test_label))\n",
    "neural_valid_label = target_transform(np.array(valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(331, 780)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(neural_train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 780), (71, 40, 56, 1))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(neural_train_label), np.shape(neural_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_file(neural_train, 'neural_train')\n",
    "save_file(neural_train_label, 'neural_train_label')\n",
    "save_file(neural_test, 'neural_test')\n",
    "save_file(neural_test_label, 'neural_test_label')\n",
    "save_file(neural_valid, 'neural_valid')\n",
    "save_file(neural_valid_label, 'neural_valid_label')\n",
    "\n",
    "# save_file(machine_train, 'machine_train')\n",
    "# save_file(machine_train_label, 'machine_train_label')\n",
    "# save_file(machine_test, 'machine_test')\n",
    "# save_file(machine_test_label, 'machine_test_label')\n",
    "# save_file(machine_valid, 'machine_valid')\n",
    "# save_file(machine_valid_label, 'machine_valid_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0, 1, 1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
