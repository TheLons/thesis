{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "import warnings\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential, Input, Model\n",
    "from keras.layers import Dense, Dropout, Flatten, LSTM, Embedding, Activation, Add, Bidirectional\n",
    "from keras.layers import Conv2D, MaxPooling1D, AveragePooling1D, MaxPooling2D, TimeDistributed, Reshape\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers.advanced_activations import LeakyReLU, ReLU, ELU\n",
    "from keras.regularizers import l2 # L2-regularisation\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_name):\n",
    "    pkl_file = open(data_name + '.pkl', 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data\n",
    "\n",
    "print('Loading data...')\n",
    "folder = '../input/pairwise/'\n",
    "folder2 = '../input/aminodataset/'\n",
    "\n",
    "train = np.array(load_data(folder + 'train'))\n",
    "train_label = load_data(folder2 + 'train_label')\n",
    "test = np.array(load_data(folder + 'test'))\n",
    "test_label = load_data(folder2 + 'test_label')\n",
    "valid = np.array(load_data(folder + 'valid'))\n",
    "valid_label = load_data(folder2 + 'valid_label')\n",
    "print('Data are loaded')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, np.shape(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train.reshape(train.shape[0], train.shape[1], train.shape[2])\n",
    "# test = test.reshape(test.shape[0], test.shape[1], test.shape[2])\n",
    "# valid = valid.reshape(valid.shape[0], valid.shape[1], valid.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape, np.shape(train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_bn(inputs):\n",
    "    relu = (ELU(alpha=0.1))(inputs)\n",
    "    norm = (BatchNormalization())(relu)\n",
    "    \n",
    "    return norm\n",
    "\n",
    "\n",
    "def residual_block_identity(x, l2_lambda):\n",
    "        \n",
    "    y = (Conv2D(filters = 16, \n",
    "                kernel_size = (5, 5), \n",
    "                activation='linear', \n",
    "                W_regularizer=l2(l2_lambda), \n",
    "                padding='same'))(x)\n",
    "    \n",
    "    y = (LeakyReLU(alpha=0.3))(y)\n",
    "    \n",
    "    y = (Conv2D(filters = 32, \n",
    "                kernel_size = (5, 5), \n",
    "                activation='linear', \n",
    "                W_regularizer=l2(l2_lambda), \n",
    "                padding='same'))(y)\n",
    "    \n",
    "    y = (LeakyReLU(alpha=0.3))(y)\n",
    "    \n",
    "    out = (Add())([x, y])\n",
    "    out = (MaxPooling2D(pool_size = (2, 2), padding = 'same'))(out)\n",
    "        \n",
    "    out = (Dropout(0.5))(y)\n",
    "    \n",
    "    return out\n",
    "\n",
    "\n",
    "def residual_block_convolutional(x, l2_lambda):\n",
    "    \n",
    "#     f1, f2, f3 = filters\n",
    "        \n",
    "    y = (Conv2D(filters = 16, \n",
    "               kernel_size = (1, 1),\n",
    "               strides = (2, 2),\n",
    "               activation = 'linear'))(x)\n",
    "    \n",
    "    y = (LeakyReLU(alpha=0.3))(y)\n",
    "    \n",
    "    y = (Conv2D(filters = 32, \n",
    "               kernel_size = (5, 5),\n",
    "               padding = \"same\", \n",
    "               activation ='linear'))(y)\n",
    "\n",
    "    y = (LeakyReLU(alpha=0.3))(y)\n",
    "    \n",
    "    x = (Conv2D(filters = 32, \n",
    "               kernel_size = (1, 1),\n",
    "               strides = (2, 2),\n",
    "               padding = \"same\", \n",
    "               activation ='linear'))(x)\n",
    "    \n",
    "    y = (LeakyReLU(alpha=0.3))(y)\n",
    "        \n",
    "    out = (Add())([x, y])\n",
    "    out = (MaxPooling2D(pool_size = (2, 2), padding = 'same'))(out)\n",
    "    out = (Dropout(0.5))(out)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet(input_shape, out_shape, mm):\n",
    "    \n",
    "    l2_lambda = 0.0001\n",
    "    num_blocks_list = [2]\n",
    "    \n",
    "    inputs = Input(input_shape)\n",
    "        \n",
    "    for i in range(len(num_blocks_list)):\n",
    "        \n",
    "        num_blocks = num_blocks_list[i]\n",
    "        \n",
    "        if i == 0:\n",
    "            t = residual_block_convolutional(inputs, l2_lambda = l2_lambda)\n",
    "        else:\n",
    "            t = residual_block_convolutional(t, l2_lambda = l2_lambda)\n",
    "        \n",
    "        for j in range(num_blocks):\n",
    "            t = residual_block_identity(t, l2_lambda = l2_lambda)\n",
    "        \n",
    "    t = (Conv2D(kernel_size = (5, 5),\n",
    "           strides = (1, 1),\n",
    "           filters = 1,\n",
    "           padding = \"same\"))(t)\n",
    "    \n",
    "    t = (Reshape((t.shape[1], t.shape[2])))(t)\n",
    "    \n",
    "#     layer = (Flatten())(t)\n",
    "    \n",
    "    layer = (Bidirectional(LSTM(16, return_sequences=True)))(t)\n",
    "    layer = (Dropout(0.4))(layer)\n",
    "    \n",
    "    layer = (Bidirectional(LSTM(32, return_sequences=True)))(layer)\n",
    "    layer = (Dropout(0.4))(layer)\n",
    "    \n",
    "    layer = (Bidirectional(LSTM(64, return_sequences=True)))(t)\n",
    "    layer = (Dropout(0.4))(layer)\n",
    "    \n",
    "    layer = (Bidirectional(LSTM(128, return_sequences=True)))(t)\n",
    "    layer = (Dropout(0.4))(layer)\n",
    "    \n",
    "    layer = (Bidirectional(LSTM(256, return_sequences=True)))(t)\n",
    "    layer = (Dropout(0.4))(layer)\n",
    "    \n",
    "    layer = (Bidirectional(LSTM(512)))(layer)\n",
    "    layer = (Dropout(0.4))(layer)\n",
    "    \n",
    "#     layer = (Dense((mm), activation='linear', W_regularizer=l2(l2_lambda)))(layer)\n",
    "#     layer = (LeakyReLU(alpha=0.1))(layer)\n",
    "#     layer = (Dropout(0.5))(layer)\n",
    "    finish = []\n",
    "    \n",
    "#     output = Dense(out_shape, activation='softmax', name='main_output'(layer4)\n",
    "\n",
    "    for i in range(int((mm ** 2 - mm) / 2)):\n",
    "        output = Dense(out_shape, activation='softmax', name='main_output'+str(i))(layer)\n",
    "        finish.append(output)\n",
    "        \n",
    "    model = Model(inputs = [inputs], outputs = finish)\n",
    "    model.compile(loss = \"categorical_crossentropy\", \n",
    "                  optimizer = keras.optimizers.Adam(lr=0.001))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "epochs = 40\n",
    "mm = 40\n",
    "\n",
    "model = resnet((train.shape[1], train.shape[2], 1), 2, mm)\n",
    "\n",
    "print('Start training...')\n",
    "history = model.fit(train, list(train_label), batch_size = batch_size, epochs = epochs, verbose = 0,\n",
    "                          validation_data=(valid, list(valid_label)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.savefig('resnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = model.predict(test)\n",
    "\n",
    "print(np.shape(predicted))\n",
    "print(np.shape(test_label))\n",
    "\n",
    "output = open('predicted_res' + '.pkl', 'wb')\n",
    "pickle.dump(predicted, output)\n",
    "output.close()\n",
    "\n",
    "output = open('test_res' + '.pkl', 'wb')\n",
    "pickle.dump(test_label, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "import operator\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "\n",
    "\n",
    "def score(test_label, predicted, metric):\n",
    "    \n",
    "    predicted = np.array(predicted).reshape(780 * 73, 2)\n",
    "    test_label = np.array(test_label).reshape(780 * 73, 2)\n",
    "    \n",
    "    id_score = {}\n",
    "    pred = []\n",
    "    test = []\n",
    "    \n",
    "    L = []\n",
    "    L_2 = []\n",
    "    L_5 = []\n",
    "    L_10 = []\n",
    "    \n",
    "    for i in range(len(predicted)):\n",
    "        id_score[i] = predicted[i][1]\n",
    "        \n",
    "    for key, value in reversed(sorted(id_score.items(), key=operator.itemgetter(1))):\n",
    "        pred.append(np.argmax([1 - value, value]))\n",
    "        test.append(np.argmax(test_label[key]))\n",
    "        \n",
    "    if metric == 'recall':\n",
    "        \n",
    "        L.append(recall_score(test, pred))\n",
    "        L_2.append(recall_score(test[:len(test) // 2], pred[:len(pred) // 2]))\n",
    "        L_5.append(recall_score(test[:len(test) // 5], pred[:len(pred) // 5]))\n",
    "        L_10.append(recall_score(test[:len(test) // 10], pred[:len(pred) // 10]))\n",
    "        \n",
    "    elif metric == 'f1':\n",
    "        \n",
    "        L.append(f1_score(test, pred))\n",
    "        L_2.append(f1_score(test[:len(test) // 2], pred[:len(pred) // 2]))\n",
    "        L_5.append(f1_score(test[:len(test) // 5], pred[:len(pred) // 5]))\n",
    "        L_10.append(f1_score(test[:len(test) // 10], pred[:len(pred) // 10]))\n",
    "        \n",
    "    elif metric == 'precision':\n",
    "        \n",
    "        L.append(precision_score(test, pred))\n",
    "        L_2.append(precision_score(test[:len(test) // 2], pred[:len(pred) // 2]))\n",
    "        L_5.append(precision_score(test[:len(test) // 5], pred[:len(pred) // 5]))\n",
    "        L_10.append(precision_score(test[:len(test) // 10], pred[:len(pred) // 10]))\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        raise ValueError('No metric was found')\n",
    "            \n",
    "    return L, L_2, L_5, L_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_results(test_label, proba):\n",
    "    \n",
    "    # f1 score\n",
    "    \n",
    "    L, L_2, L_5, L_10 = score(test_label, proba, 'f1')\n",
    "    print('F1 score:')\n",
    "    print('L:', L)\n",
    "    print('L_2:', L_2)\n",
    "    print('L_5:', L_5)\n",
    "    print('L_10:', L_10)\n",
    "    \n",
    "    # precision score\n",
    "    \n",
    "    L, L_2, L_5, L_10 = score(test_label, proba, 'precision')\n",
    "    print('Precision score:')\n",
    "    print('L:', L)\n",
    "    print('L_2:', L_2)\n",
    "    print('L_5:', L_5)\n",
    "    print('L_10:', L_10)\n",
    "    \n",
    "    \n",
    "    # recall score\n",
    "    \n",
    "    L, L_2, L_5, L_10 = score(test_label, proba, 'recall')\n",
    "    print('Recall score:')\n",
    "    print('L:', L)\n",
    "    print('L_2:', L_2)\n",
    "    print('L_5:', L_5)\n",
    "    print('L_10:', L_10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_results(test_label, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
