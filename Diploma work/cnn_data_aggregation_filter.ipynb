{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data aggregation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading train_data and contact matrix\n",
      "Loaded successfully\n",
      "8765\n",
      "6905\n",
      "6813\n",
      "Amount of proteins, which we have after bounding:  403\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import trange\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "print('Loading train_data and contact matrix')\n",
    "\n",
    "def load_data(data_name):\n",
    "    pkl_file = open(data_name + '.pkl', 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data\n",
    "\n",
    "#  Load data and target\n",
    "data_train = load_data('train_data')\n",
    "two_matrix = load_data('two_matrix_200')\n",
    "num_classes = 2\n",
    "print('Loaded successfully')\n",
    "\n",
    "data_features = pd.read_csv('pdb_and_features.csv')\n",
    "data_features = data_features.reset_index(drop=True)\n",
    "print(len(data_train))\n",
    "print(len(two_matrix))\n",
    "print(len(data_features))\n",
    "\n",
    "protein_len = []\n",
    "pdb_200 = []\n",
    "\n",
    "low_border = 15\n",
    "high_border = 30\n",
    "\n",
    "s = 0\n",
    "for i in range(len(two_matrix)):\n",
    "    if (np.shape(two_matrix[i][2])[0] <= high_border) and (np.shape(two_matrix[i][2])[0] >= low_border):\n",
    "        s +=1\n",
    "\n",
    "print('Amount of proteins, which we have after bounding: ', s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "6813",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-842766cd5d51>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m     \u001b[0;32melif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFASTA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mhigh_border\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_features\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFASTA\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlow_border\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         train.append([data_features.pdb_name[i], \n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1069\u001b[0m         \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1070\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1071\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1072\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1073\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.8/lib/python3.8/site-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_value\u001b[0;34m(self, series, key)\u001b[0m\n\u001b[1;32m   4728\u001b[0m         \u001b[0mk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convert_scalar_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"getitem\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4729\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4730\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtz\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tz\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4731\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4732\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mholds_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_boolean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 6813"
     ]
    }
   ],
   "source": [
    "#  Apply zero-padding to make same size for all train and target samples\n",
    "\n",
    "target = []\n",
    "mm = high_border\n",
    "\n",
    "for i in range(len(two_matrix)):\n",
    "    \n",
    "    if (high_border >= np.shape(two_matrix[i][2])[0]) and (np.shape(two_matrix[i][2])[0] >= low_border):\n",
    "        \n",
    "        f = np.zeros((mm-np.shape(two_matrix[i][2])[0], np.shape(two_matrix[i][2])[0]))\n",
    "        f1 = np.zeros((mm, mm-np.shape(two_matrix[i][2])[0]))\n",
    "        bot = np.concatenate((two_matrix[i][2], f), axis=0)\n",
    "        target.append([two_matrix[i][0], np.concatenate((bot, f1), axis=1), len(two_matrix[i][2])])\n",
    "        \n",
    "\n",
    "train = []\n",
    "mm = high_border\n",
    "\n",
    "for i in range(len(data_train)):\n",
    "    \n",
    "    if (high_border >= np.shape(data_train[i][1])[0]) and (len(data_features.FASTA[i]) <= high_border) and \\\n",
    "            (len(data_features.FASTA[i]) >= low_border):\n",
    "        \n",
    "        f = np.zeros((mm-np.shape(data_train[i][1])[0], np.shape(data_train[i][1])[1]))\n",
    "        train.append([data_features.pdb_name[i], \n",
    "                      np.concatenate((data_train[i][1], f), axis=0), \n",
    "                      len(data_features.FASTA[i]),\n",
    "                      data_features.FASTA[i]])\n",
    "        \n",
    "        \n",
    "        \n",
    "    elif (len(data_features.FASTA[i]) <= high_border) and (len(data_features.FASTA[i]) >= low_border):\n",
    "        \n",
    "        train.append([data_features.pdb_name[i], \n",
    "                      data_train[i][1][:mm], \n",
    "                      len(data_features.FASTA[i]), \n",
    "                      data_features.FASTA[i]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train - target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train = []\n",
    "real_target = []\n",
    "\n",
    "for i in range(len(target)):\n",
    "    \n",
    "    for j in range(len(train)):\n",
    "        \n",
    "        if train[j][0] == target[i][0]:\n",
    "            real_train.append(train[j])\n",
    "            real_target.append(target[i])\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((474, 4), (474, 3))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(real_train), np.shape(real_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_train[2][2], real_target[2][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_train = load_data('righttrain')\n",
    "real_target = load_data('righttarget')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, train_val_test, train_label, target_val_test = train_test_split(real_train, real_target, test_size=0.3, random_state=13)\n",
    "test, valid, test_label, valid_label = train_test_split(train_val_test, target_val_test, test_size=0.5, random_state=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((273, 3), (58, 3))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train), np.shape(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Statistical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features: affinity score matrix, length of each protein, distance between every amino acid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Affinity score matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affinity(a, b) = Contact(A, B) / (Contact(A, B) + NonContact(A, B))\n",
    "\n",
    "separation distance $\\geq$ 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def affinity_matrix(seq, two_matrix):\n",
    "    \n",
    "    # 20 is the number of amino acids\n",
    "    aa = {'A' : 0, 'C' : 1, 'D' : 2, 'E' : 3, 'F' : 4, 'G' : 5, 'H' : 6, 'I' : 7, 'K' : 8, 'L' : 9, \n",
    "          'M' : 10, 'N' : 11, 'P' : 12, 'Q' : 13, 'R' : 14, 'S' : 15, 'T' : 16, 'V' : 17, 'W' : 18, 'Y' : 19}\n",
    "    \n",
    "    aff_matrix = [[0] * 20 for i in range(20)]\n",
    "    matrix = [[0] * 20 for i in range(20)]\n",
    "        \n",
    "    if len(seq) != np.shape(two_matrix)[0]:\n",
    "        return np.array(aff_matrix), np.array(matrix), 0\n",
    "    \n",
    "    for i in range(len(seq)):\n",
    "        for j in range(i + 6, len(seq)):\n",
    "            \n",
    "            matrix[aa[seq[i]]][aa[seq[j]]] += 1\n",
    "            matrix[aa[seq[j]]][aa[seq[i]]] += 1\n",
    "                \n",
    "            if two_matrix[i][j] == 1:\n",
    "                \n",
    "                aff_matrix[aa[seq[i]]][aa[seq[j]]] += 1\n",
    "                aff_matrix[aa[seq[j]]][aa[seq[i]]] += 1\n",
    "                \n",
    "    return np.array(aff_matrix), np.array(matrix), 1\n",
    "\n",
    "\n",
    "def get_probability(first, second, aff_matrix):\n",
    "    \n",
    "    aa = {'A' : 0, 'C' : 1, 'D' : 2, 'E' : 3, 'F' : 4, 'G' : 5, 'H' : 6, 'I' : 7, 'K' : 8, 'L' : 9, \n",
    "      'M' : 10, 'N' : 11, 'P' : 12, 'Q' : 13, 'R' : 14, 'S' : 15, 'T' : 16, 'V' : 17, 'W' : 18, 'Y' : 19}\n",
    "    \n",
    "    return aff_matrix[aa[first]][aa[second]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_matrix = [[0] * 20 for i in range(20)]\n",
    "matrix = [[0] * 20 for i in range(20)]\n",
    "count = 0\n",
    "\n",
    "for i in range(len(train)):\n",
    "    for j in range(len(two_matrix)):\n",
    "        \n",
    "        if train[i][0] == two_matrix[j][0]:\n",
    "            \n",
    "            aff, m, cnt = affinity_matrix(train[i][3], two_matrix[j][2])\n",
    "            aff_matrix = np.add(aff_matrix, aff)\n",
    "            matrix = np.add(matrix, m)\n",
    "            count += cnt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "aff_matrix = np.divide(aff_matrix, matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Length of each protein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_matrix = []\n",
    "\n",
    "for i in range(len(train)):\n",
    "    \n",
    "    len_matrix.append([train[i][0], len(train[i][3])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['2KGU', 35], ['1ZWU', 30], ['1HP3', 32], ['1IB9', 34], ['2JPK', 35]]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len_matrix[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 4), (331, 3))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(train), np.shape(train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train test transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some transformations to make train and target data\n",
    "# For neural networks\n",
    "\n",
    "def redo(x):\n",
    "    \n",
    "    out = []\n",
    "    for i in range(len(x)):\n",
    "        out.append(x[i][1])\n",
    "        \n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "def train_transform(x):\n",
    "    \n",
    "    x = redo(np.array(x))\n",
    "    x = np.expand_dims(x, axis=4)\n",
    "    \n",
    "    return x\n",
    "\n",
    "\n",
    "def reshape_of_labels(x):\n",
    "    \n",
    "    lst1 = [[[0 for col in range(x.shape[2])] for col in range(x.shape[0])] for row in range(x.shape[1])]\n",
    "    for i in range(len(x)):\n",
    "        for j in range(len(x[i])):\n",
    "            for k in range(len(x[i][j])):\n",
    "                lst1[j][i][k] = x[i, j, k]\n",
    "                \n",
    "    return lst1\n",
    "\n",
    "\n",
    "def triangle_target_transform(x):\n",
    "            \n",
    "    res = []\n",
    "    for i in range(x.shape[0]):\n",
    "        res.append(x[i][1][np.triu_indices(len(x[i][1]), k = 1)])\n",
    "    \n",
    "    return np.array(res)\n",
    "\n",
    "    \n",
    "def target_transform(x):\n",
    "    \n",
    "    new_x = []\n",
    "    x = triangle_target_transform(x)\n",
    "    enc = OneHotEncoder(sparse = False)\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "\n",
    "        new_x.append(enc.fit_transform(x[0].reshape(-1, 1)))\n",
    "        \n",
    "    x = reshape_of_labels(np.array(new_x))\n",
    "    \n",
    "    return np.array(x)\n",
    "\n",
    "\n",
    "def save_file(data, data_name):\n",
    "    \n",
    "    output = open(data_name + '.pkl', 'wb')\n",
    "    pickle.dump(data, output)\n",
    "    output.close()\n",
    "    \n",
    "    \n",
    "def machine_train_transform(x, aff_matrix):\n",
    "    \n",
    "    out_matrix = []\n",
    "    out = []\n",
    "    dist = []\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        out_matrix = []\n",
    "        \n",
    "        for j in range(len(x[i][1])):\n",
    "            for k in range(j + 1, len(x[i][1])):\n",
    "                \n",
    "                if j < x[i][2] and k < x[i][2]:\n",
    "                    pair = [k - j, get_probability(x[i][3][j], x[i][3][k], aff_matrix), len(x[i][3])]\n",
    "\n",
    "                    out_matrix.append(np.concatenate([\n",
    "                        x[i][1][j], \n",
    "                        x[i][1][k],\n",
    "                        pair]))\n",
    "                else:\n",
    "                    pair = [0, 0, 0]\n",
    "\n",
    "                    out_matrix.append(np.concatenate([\n",
    "                        np.zeros(len(x[i][1][j])), \n",
    "                        np.zeros(len(x[i][1][k])),\n",
    "                        pair]))\n",
    "                     \n",
    "        out.append(np.array(out_matrix))\n",
    "            \n",
    "    out = np.array(out)\n",
    "    out = np.expand_dims(out, axis=4)\n",
    "    \n",
    "    return np.array(out)\n",
    "\n",
    "\n",
    "def machine_target_transform(x):\n",
    "    \n",
    "    x = triangle_target_transform(x)\n",
    "    \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-253-f7ec6b00f094>:93: DeprecationWarning: Both axis > a.ndim and axis < -a.ndim - 1 are deprecated and will raise an AxisError in the future.\n",
      "  out = np.expand_dims(out, axis=4)\n"
     ]
    }
   ],
   "source": [
    "def batch(iterable, n = 1):\n",
    "    \n",
    "    l = len(iterable)\n",
    "    \n",
    "    for ndx in range(0, l, n):\n",
    "        \n",
    "        yield iterable[ndx : min(ndx + n, l)]\n",
    "\n",
    "machine_train = []\n",
    "machine_test = []\n",
    "machine_valid = []\n",
    "        \n",
    "for x in batch(train, 10):\n",
    "    result = machine_train_transform(x, aff_matrix)\n",
    "    \n",
    "    for i in range(len(result)):\n",
    "        machine_train.append(result[i])\n",
    "\n",
    "for x in batch(test, 10):\n",
    "    result = machine_train_transform(x, aff_matrix)\n",
    "    \n",
    "    for i in range(len(result)):\n",
    "        machine_test.append(result[i])\n",
    "    \n",
    "for x in batch(valid, 10):\n",
    "    result = machine_train_transform(x, aff_matrix)\n",
    "    \n",
    "    for i in range(len(result)):\n",
    "        machine_valid.append(result[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_train = np.array(machine_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test data for neural networks and machine learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [],
   "source": [
    "machine_train_label = target_transform(np.array(train_label))\n",
    "machine_test_label = target_transform(np.array(test_label))\n",
    "machine_valid_label = target_transform(np.array(valid_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((331, 780, 115, 1), (780, 331, 2))"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "machine_train.shape, machine_train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((780, 340, 2), (340, 40, 56, 1))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(neural_train_label), np.shape(neural_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save_file(neural_train, 'neural_train')\n",
    "# save_file(neural_train_label, 'neural_train_label')\n",
    "# save_file(neural_test, 'neural_test')\n",
    "# save_file(neural_test_label, 'neural_test_label')\n",
    "# save_file(neural_valid, 'neural_valid')\n",
    "# save_file(neural_valid_label, 'neural_valid_label')\n",
    "\n",
    "save_file(machine_train, 'machine_train')\n",
    "save_file(machine_train_label, 'machine_train_label')\n",
    "save_file(machine_test, 'machine_test')\n",
    "save_file(machine_test_label, 'machine_test_label')\n",
    "save_file(machine_valid, 'machine_valid')\n",
    "save_file(machine_valid_label, 'machine_valid_label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [0, 1, 1]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
