{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_all(text, dic):\n",
    "    for i, j in dic.items():\n",
    "        text = text.replace(i, j)\n",
    "    return text\n",
    "\n",
    "\n",
    "def string_to_float(a):\n",
    "    s1 = replace_all(a, rep)\n",
    "    s1 = s1.split(' ')\n",
    "    s1 = [float(i) for i in s1]\n",
    "    return s1\n",
    "\n",
    "\n",
    "def load_data(data_name):\n",
    "    pkl_file = open(data_name + '.pkl', 'rb')\n",
    "    data = pickle.load(pkl_file)\n",
    "    pkl_file.close()\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sequential data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FASTA sequences, polarity and radicals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record FASTA df: OK\n"
     ]
    }
   ],
   "source": [
    "#  Read fasta-files\n",
    "with open('./train/train.fasta', 'r') as myfile:\n",
    "    data = myfile.read().replace('\\n', '')\n",
    "    \n",
    "    \n",
    "#  Create dictionaries for classifying all aminoacids according to classe from wiki (polarity and radicals)\n",
    "rad_dic = {'G': '0', 'L': '0', 'Y': '1', 'S': '2', 'E': '3', 'Q': '4', 'D': '3', 'N': '4', 'F': '1',\n",
    "       'A': '0', 'K': '5', 'R': '5', 'H': '6', 'C': '7', 'V': '0', 'P': '6', 'W': '6', 'I': '0', 'M': '7', 'T': '2'}\n",
    "pol_dic = {'G': '0', 'L': '0', 'Y': '1', 'S': '1', 'E': '2', 'Q': '1', 'D': '2', 'N': '1', 'F': '0',\n",
    "        'A': '0', 'K': '1', 'R': '1', 'H': '3', 'C': '0', 'V': '0', 'P': '0', 'W': '0', 'I': '0', 'M': '0', 'T': '1'}\n",
    "\n",
    "\n",
    "bad_prot = []\n",
    "pdb_name = ''\n",
    "seq = ''\n",
    "j = 0\n",
    "fasta_df = pd.DataFrame()\n",
    "mm = 0\n",
    "\n",
    "\n",
    "#  Record protein name, fasta sequences, radical and polarity classes into dataframe\n",
    "for i in range(len(data) - 1):\n",
    "    seq = ''\n",
    "    \n",
    "    if data[i] == '$' and data[i+5] == '%':\n",
    "        pdb_name = data[i+1:i+5]\n",
    "        \n",
    "    if data[i] == '%':\n",
    "        j = i+1\n",
    "        \n",
    "        while data[j] != '$' and j != len(data)-1:\n",
    "            \n",
    "            if data[j] not in rad_dic:\n",
    "                if pdb_name not in bad_prot:\n",
    "                    bad_prot.append(pdb_name)\n",
    "            \n",
    "            seq += data[j]\n",
    "            j = j + 1\n",
    "            \n",
    "            if j == len(data) - 1:\n",
    "                seq += data[j]\n",
    "                \n",
    "        if len(seq) > mm:\n",
    "            mm = len(seq)\n",
    "            \n",
    "        replace_all(seq, rad_dic)\n",
    "        temp_df = pd.DataFrame({'pdb_name': [pdb_name], 'FASTA':[seq], 'Radical':[replace_all(seq, rad_dic)]\n",
    "                           , 'Polarity':[replace_all(seq, pol_dic)]})\n",
    "        fasta_df = pd.concat([fasta_df, temp_df], ignore_index=True)\n",
    "        \n",
    "        \n",
    "print(\"Record FASTA df: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record data: OK\n"
     ]
    }
   ],
   "source": [
    "output = open('fasta1.pkl', 'wb')\n",
    "pickle.dump(fasta_df, output)\n",
    "output.close()\n",
    "print(\"Record data: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PSSM matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record PSSM df: OK\n"
     ]
    }
   ],
   "source": [
    "#  Read PSSM matrix and also record it into dataframe\n",
    "file = open('./train/train.pssm', 'r')\n",
    "pssm = file.readlines()\n",
    "rep = {'G ':'', 'L ':'', 'Y ':'', 'S ':'', 'E ':'', 'Q ':'', 'D ':'', 'N ':'', 'F ':'', \n",
    "       'A ':'', 'K ':'', 'R ':'', 'H ':'', 'C ':'', 'V ':'', 'P ':'', 'W ':'', 'I ':'', 'M ':'', 'X ':'', 'T ':'', '\\n':''}\n",
    "\n",
    "\n",
    "pssm_df = pd.DataFrame()\n",
    "gd = []\n",
    "j = 0\n",
    "\n",
    "\n",
    "for i in range(len(pssm)-1, -1, -1):\n",
    "    \n",
    "    if pssm[i][0] == '>':\n",
    "        gd = list(reversed(gd))\n",
    "        temp_df = pd.DataFrame({'PSSM': [gd]})\n",
    "        pssm_df = pd.concat([pssm_df, temp_df], ignore_index = True)\n",
    "        gd = []\n",
    "        \n",
    "    if pssm[i][0]!='>':\n",
    "        gd.append(string_to_float(pssm[i]))\n",
    "\n",
    "        \n",
    "print(\"Record PSSM df: OK\")\n",
    "\n",
    "\n",
    "pssm_df = pssm_df.iloc[::-1]\n",
    "pssm_df = pssm_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record data: OK\n"
     ]
    }
   ],
   "source": [
    "output = open('pssm1.pkl', 'wb')\n",
    "pickle.dump(pssm_df, output)\n",
    "output.close()\n",
    "print(\"Record data: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solvent accessibility and secondary structure classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record SS and ACC df: OK\n"
     ]
    }
   ],
   "source": [
    "# Read solvent accessibility and secondary structure classes\n",
    "file = open('./train/train.acc', 'r')\n",
    "acc = file.readlines()\n",
    "\n",
    "\n",
    "file = open('./train/train.ss', 'r')\n",
    "ss = file.readlines()\n",
    "ss_acc_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "for i in range(len(ss)):\n",
    "    if i%2 != 0:\n",
    "        temp = pd.DataFrame({'SS': [ss[i].replace('\\n', '')], 'ACC':[acc[i].replace('\\n', '')]})\n",
    "        ss_acc_df = pd.concat([ss_acc_df, temp], ignore_index=True)\n",
    "        \n",
    "        \n",
    "print(\"Record SS and ACC df: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SS</th>\n",
       "      <th>ACC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CECCHHHHHHHHHHCCCCCECCECHHHHHHHHHHHHCCECCCEEEC...</td>\n",
       "      <td>ee-eeee--e--ee-e-eeeee-e--------ee--e-e-e-eeee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CECCHHHHHHHHHHCCCCCECCECHHHHHHHHHHHHCCECCCEEEE...</td>\n",
       "      <td>ee-ee-e--e--eeee-ee-ee-e--------ee--e-e-e-eeee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CECCHHHHHHHHHHCCCCCECCECHHHHHHHHHHHHCCECCCEEEE...</td>\n",
       "      <td>ee-ee-e--e--eeee-ee-ee-e--------ee--e-e-e-eeee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CECCHHHHHHHHHHCCCCCECCECHHHHHHHHHHHHCCECCCEEEC...</td>\n",
       "      <td>ee-eeee--e--ee-e-eeeee-e--------ee--e-e-e-eeee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCHHHHHHHHHCCEEEEEECCCCCEEEECCEEEECCCCHHHHHHHH...</td>\n",
       "      <td>ee-ee--ee--e-eee--eeeeee-------e--eeeeeee--ee-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8784</th>\n",
       "      <td>CCCCCCCEEEECCCCCCCCCC</td>\n",
       "      <td>eeeee-------eeeee-eee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8785</th>\n",
       "      <td>CCCCEEEECCCECCCCECCHHHEEEECCCCCCCEHHHHHHHCCCEE...</td>\n",
       "      <td>eee-----eee-eeeee-eee--eeee-eee--e-e--ee-ee-e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8786</th>\n",
       "      <td>CCCCEEEEEEEECCCCEEEECCCCCEEEECCCHHHHHHCCCEEEEE...</td>\n",
       "      <td>ee-ee-------eee----eeeeee----e-eeeeeee-------e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8787</th>\n",
       "      <td>CCCCEEEECCCECCCCECCHHHEEEECCCCCCCEHHHHHHHCCCEE...</td>\n",
       "      <td>eee-----eee-eeeee-eee--eeee-eee--e-e--ee-ee-e-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8788</th>\n",
       "      <td>CCCHHHHHHHHHECCCCCCCCCCCHHHHHHHHCCCCCCCCCCEEEE...</td>\n",
       "      <td>eeee-ee-e-----eeeee-eeee--ee--ee-e--eee--ee---...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8789 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     SS  \\\n",
       "0     CECCHHHHHHHHHHCCCCCECCECHHHHHHHHHHHHCCECCCEEEC...   \n",
       "1     CECCHHHHHHHHHHCCCCCECCECHHHHHHHHHHHHCCECCCEEEE...   \n",
       "2     CECCHHHHHHHHHHCCCCCECCECHHHHHHHHHHHHCCECCCEEEE...   \n",
       "3     CECCHHHHHHHHHHCCCCCECCECHHHHHHHHHHHHCCECCCEEEC...   \n",
       "4     CCHHHHHHHHHCCEEEEEECCCCCEEEECCEEEECCCCHHHHHHHH...   \n",
       "...                                                 ...   \n",
       "8784                              CCCCCCCEEEECCCCCCCCCC   \n",
       "8785  CCCCEEEECCCECCCCECCHHHEEEECCCCCCCEHHHHHHHCCCEE...   \n",
       "8786  CCCCEEEEEEEECCCCEEEECCCCCEEEECCCHHHHHHCCCEEEEE...   \n",
       "8787  CCCCEEEECCCECCCCECCHHHEEEECCCCCCCEHHHHHHHCCCEE...   \n",
       "8788  CCCHHHHHHHHHECCCCCCCCCCCHHHHHHHHCCCCCCCCCCEEEE...   \n",
       "\n",
       "                                                    ACC  \n",
       "0     ee-eeee--e--ee-e-eeeee-e--------ee--e-e-e-eeee...  \n",
       "1     ee-ee-e--e--eeee-ee-ee-e--------ee--e-e-e-eeee...  \n",
       "2     ee-ee-e--e--eeee-ee-ee-e--------ee--e-e-e-eeee...  \n",
       "3     ee-eeee--e--ee-e-eeeee-e--------ee--e-e-e-eeee...  \n",
       "4     ee-ee--ee--e-eee--eeeeee-------e--eeeeeee--ee-...  \n",
       "...                                                 ...  \n",
       "8784                              eeeee-------eeeee-eee  \n",
       "8785  eee-----eee-eeeee-eee--eeee-eee--e-e--ee-ee-e-...  \n",
       "8786  ee-ee-------eee----eeeeee----e-eeeeeee-------e...  \n",
       "8787  eee-----eee-eeeee-eee--eeee-eee--e-e--ee-ee-e-...  \n",
       "8788  eeee-ee-e-----eeeee-eeee--ee--ee-e--eee--ee---...  \n",
       "\n",
       "[8789 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss_acc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record data: OK\n"
     ]
    }
   ],
   "source": [
    "output = open('acc1.pkl', 'wb')\n",
    "pickle.dump(ss_acc_df, output)\n",
    "output.close()\n",
    "print(\"Record data: OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# All to one"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop \"bad proteins\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concatenate dfs: OK\n",
      "Drop bad proteins: OK\n"
     ]
    }
   ],
   "source": [
    "two_matrix = load_data('two_matrix_200')\n",
    "\n",
    "# Concatenate all dataframes into one\n",
    "result = pd.concat([fasta_df, ss_acc_df, pssm_df], axis=1, sort=False)\n",
    "print(\"Concatenate dfs: OK\")\n",
    "\n",
    "# #  Delete proteins with untypical aminoacids in sequence or the ones with different sequence size\n",
    "# bad = []\n",
    "\n",
    "# for i in range(len(two_matrix)):\n",
    "#     for j in range(len(result)):\n",
    "        \n",
    "#         if two_matrix[i][0] == result['pdb_name'][j]:\n",
    "            \n",
    "#             if len(two_matrix[i][2]) != len(result.FASTA[j]) or result.pdb_name.iloc[i] in bad_prot:\n",
    "#                 bad.append(j)\n",
    "        \n",
    "# result = result.drop(bad)\n",
    "# result = result.reset_index(drop=True)\n",
    "# print(\"Drop bad proteins: OK\")\n",
    "\n",
    "bad = []\n",
    "for i in range(len(result)):\n",
    "    if result.pdb_name.iloc[i] in bad_prot:\n",
    "        bad.append(i)\n",
    "result = result.drop(bad)\n",
    "result = result.reset_index(drop=True)\n",
    "print(\"Drop bad proteins: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = result.drop(927)\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6812, 7)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-73-ec03e475eaa7>:1: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  result.pdb_name.to_csv('good_prot.csv', index=False)\n"
     ]
    }
   ],
   "source": [
    "result.pdb_name.to_csv('good_prot.csv', index=False)\n",
    "result.to_csv('pdb_and_features.csv', header='pdb_name')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Binarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "asd = []\n",
    "for i in range(len(result)):\n",
    "        \n",
    "    fas = list(result.FASTA[i])\n",
    "    ss1 = list(result.SS[i])\n",
    "    acc1 = list(result.ACC[i])\n",
    "    pol = list(result.Polarity[i])\n",
    "    rad = list(result.Radical[i])\n",
    "    \n",
    "    lb = preprocessing.LabelBinarizer()\n",
    "    lb1 = preprocessing.LabelBinarizer()\n",
    "    lb2 = preprocessing.LabelBinarizer()\n",
    "    lb3 = preprocessing.LabelBinarizer()\n",
    "    lb4 = preprocessing.LabelBinarizer()\n",
    "    \n",
    "    lb.fit(['G', 'L', 'Y', 'S', 'E', 'Q', 'D', 'N', 'F', 'A', 'K', 'R', 'H', 'C', 'V', 'P', 'W', 'I', 'M', 'T'])\n",
    "    a = lb.transform(fas)\n",
    "    lb1.fit(['C', 'H', 'E'])\n",
    "    b = lb1.transform(ss1)\n",
    "    lb3.fit(['e', '-'])\n",
    "    c = lb3.transform(acc1)\n",
    "    lb2.fit(['0', '1', '2', '3', '4', '5', '6', '7'])\n",
    "    d = lb2.transform(rad)\n",
    "    lb4.fit(['0', '1', '2', '3'])\n",
    "    e = lb4.transform(rad)\n",
    "    \n",
    "    pdb1 = np.concatenate((a, b, c, d, e, result.PSSM[i]), axis=1)\n",
    "    asd.append([result['pdb_name'][i], pdb1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save to files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record data: OK\n"
     ]
    }
   ],
   "source": [
    "#  Save final data into pickle file\n",
    "output = open('train_data.pkl', 'wb')\n",
    "pickle.dump(asd, output)\n",
    "output.close()\n",
    "print(\"Record data: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record data: OK\n"
     ]
    }
   ],
   "source": [
    "output = open('FASTA.pkl', 'wb')\n",
    "pickle.dump(fasta, output)\n",
    "output.close()\n",
    "print(\"Record data: OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
